
# PGen: Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation

Implementation of our paper "Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation" 

## NEWS
08/05/2023: Updated pseudo gloss-text pair data in `.data/DA_paralle_sample/Zh`. Generated by PGen and mT5, featuring improved scaling and height quality! 
(left out in the last version. Sorry). 

## Brief Introduction

Sign language gloss translation aims to translate the sign glosses into spoken language texts, which is challenging due to the scarcity of labeled gloss-text parallel data. Back translation (**BT**), which generates pseudo-parallel data by translating in-domain spoken language texts into sign glosses, has been applied to alleviate the data scarcity problem. However, the lack of large-scale high-quality in-domain spoken language text data limits the effect of BT. In this paper, to overcome the limitation, we propose a **P**rompt based domain text **Gen**eration (**PGen**) approach to produce the large-scale in-domain spoken language text data. Specifically, PGEN randomly concatenates sentences from the original in-domain spoken language text data as prompts to induce a pre-trained language model (i.e., GPT-2) to generate spoken language texts in a similar style. Experimental results on three benchmarks of sign language gloss translation in varied languages demonstrate that BT with spoken language texts generated by PGEN significantly outperforms the compared methods. In addition, as the scale of spoken language texts generated by PGEN increases, the BT technique can achieve further improvements, demonstrating the effectiveness of our approach. We release the code and data for facilitating future research in this field.
<div align="center">
    <img src="/image/framework.jpg" width="70%" title="Framework of Prompt based domain text Generation."</img>
    <p class="image-caption">Figure 1: Framework of prompt based domain texts generation.</p>
</div>


## Reference Performance
We conduct both intrinsic and extrinsic evaluations for the proposed PGen approach.

### 1. Intrinsic Evaluations
**A) The word frequencies for the four monolingual corpus which gained by different methods.**


<div align="center">
    <img src="/image/word_distribution.jpg" width="50%" title="Framework of Self-training with Uncertainty-Based Sampling."</img>
    <p class="image-caption">Figure 2: The word frequency distribution on different types of monolingual corpora. The X-axis represents different words, while the Y-axis represents word frequency.</p>
</div>

### 2. Extrinsic Evaluations

**B) The performance of the gloss-to-text translation task when scaling the used monolingual data from our PGen and the retrieved approa** 
<div align="center">
    <img src="/image/bleu_vs_scale.jpg" width="50%" title="Framework of Self-training with Uncertainty-Based Sampling."</img>
    <p class="image-caption">Figure 3: The translation performance of back-translation when scaling the used monolingual data from our PGen and the retrieved approach. The red dashed line denotes the baseline model without back-translation. </p>
</div>


**C) The performance of Gloss-to-text translation on Phoenix2014T, CSL-daily and ASLG-PC12.**

<div align="center">
    <img src="/image/gloss_text.jpg" width="70%" title="Framework of Self-training with Uncertainty-Based Sampling."</img>
    <p class="image-caption">Table 1: Gloss-to-text translation performance on Phoenix2014T, CSL-daily and ASLG-PC12.</p>
</div>


## Implementation

### 1. Installation
This code is based on [transformers](https://github.com/huggingface/transformers) for PGen and [fairseq](https://github.com/facebookresearch/fairseq) for gloss-to-text translation. You can follow their pages to install. 


### 2. Finetuning GPT
You can refer to [transformers-language-modeling](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling) to finetuning a pre-trained GPT. Simply, you also can follow our script `bash finetuning_GPT.sh` to quick start.

### 3.  In-domain Data Generation

You can follow the documents of [OpenAI GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2) to generate the sentences. Also, we give a script `bash generate_in_domain_sentences.sh` to support. 



There, we give a large in-domain monolingual texts for SLT tasks (Phoenix2014T, CSL-daily and ASLG-PC12). 

You can find them in `data/PGen_monolingual/*` and get a quick start when apply scaling BT to sign language translation.


### 4. Get result on sign language  gloss translation

You can follow [fairseq](https://github.com/facebookresearch/fairseq) or [mT5](https://github.com/google-research/multilingual-t5) to train the translation models (e.g. text-to-gloss or gloss-to-text) 

We give some based script in `./G2T/[ASL | DSL | CSL]`, which are also work for T2G by reversing source language tag and target one. 



